{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook demonstrates how to reduce the bias during \"In-processing\" stage using AI 360 Fairness toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-processing algorithm\n",
    "A bias mitigation algorithm that is applied to a model during its training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert your credentials as credentials in the below cell\n",
    "Click on dropdown from Pipeline_LabelEncoder-0.1.zip under Data tab and select 'Credentials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "cos = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n",
    "    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n",
    "    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=credentials['ENDPOINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.download_file(Bucket=credentials['BUCKET'],Key='Pipeline_LabelEncoder-0.1.zip',Filename='/home/wsuser/work/Pipeline_LabelEncoder-0.1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline_LabelEncoder-0.1.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Pipeline_LabelEncoder-0.1.zip\n",
      "Building wheels for collected packages: Pipeline-LabelEncoder\n",
      "  Building wheel for Pipeline-LabelEncoder (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Pipeline-LabelEncoder: filename=Pipeline_LabelEncoder-0.1-py3-none-any.whl size=2062 sha256=b79f7abe3b5f5b526227d7e57867bccf538ea3527b0ac0308bf298044aa59af5\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/6b/4b/1e/43f3c8b97ffade4539a329b9eaa5755e4df16a248960947534\n",
      "Successfully built Pipeline-LabelEncoder\n",
      "Installing collected packages: Pipeline-LabelEncoder\n",
      "  Attempting uninstall: Pipeline-LabelEncoder\n",
      "    Found existing installation: Pipeline-LabelEncoder 0.1\n",
      "    Uninstalling Pipeline-LabelEncoder-0.1:\n",
      "      Successfully uninstalled Pipeline-LabelEncoder-0.1\n",
      "Successfully installed Pipeline-LabelEncoder-0.1\n",
      "Requirement already satisfied: aif360 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: tempeh in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (0.1.12)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (3.3.4)\n",
      "Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (0.23.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from aif360) (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas>=0.24.0->aif360) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas>=0.24.0->aif360) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from scikit-learn>=0.22.1->aif360) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from scikit-learn>=0.22.1->aif360) (2.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from matplotlib->aif360) (2.4.7)\n",
      "Requirement already satisfied: pytest in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (6.2.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (2.25.1)\n",
      "Requirement already satisfied: shap in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (0.40.0)\n",
      "Requirement already satisfied: memory-profiler in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tempeh->aif360) (0.59.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from memory-profiler->tempeh->aif360) (5.8.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (21.2.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (1.1.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (21.3)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (1.10.0)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pytest->tempeh->aif360) (0.10.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->tempeh->aif360) (3.0.4)\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (0.0.7)\n",
      "Requirement already satisfied: numba in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (0.54.1)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (4.59.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from shap->tempeh->aif360) (1.6.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from numba->shap->tempeh->aif360) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from numba->shap->tempeh->aif360) (52.0.0.post20211006)\n",
      "Requirement already satisfied: fairlearn in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from fairlearn) (1.19.2)\n",
      "Requirement already satisfied: pandas>=0.25.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from fairlearn) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from fairlearn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from fairlearn) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas>=0.25.1->fairlearn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas>=0.25.1->fairlearn) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from scikit-learn>=0.22.1->fairlearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from scikit-learn>=0.22.1->fairlearn) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pipeline_LabelEncoder-0.1.zip\n",
    "!pip install aif360\n",
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the data as Pandas Dataframe and change the name from df_data_ to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Married  Education Fraud_risk\n",
       "0   Male      No          1       Risk\n",
       "1   Male     Yes          1       Safe\n",
       "2   Male     Yes          1       Safe\n",
       "3   Male     Yes          0       Safe\n",
       "4   Male      No          1       Risk"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>703</td>\n",
       "      <td>501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730727</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443823</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender Married   Education Fraud_risk\n",
       "count     921     921  921.000000        921\n",
       "unique      2       2         NaN          2\n",
       "top      Male      No         NaN       Safe\n",
       "freq      703     501         NaN        562\n",
       "mean      NaN     NaN    0.730727        NaN\n",
       "std       NaN     NaN    0.443823        NaN\n",
       "min       NaN     NaN    0.000000        NaN\n",
       "25%       NaN     NaN    0.000000        NaN\n",
       "50%       NaN     NaN    1.000000        NaN\n",
       "75%       NaN     NaN    1.000000        NaN\n",
       "max       NaN     NaN    1.000000        NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Gender': 1}]\n",
    "unprivileged_groups = [{'Gender': 0}]\n",
    "favorable_label = 1 \n",
    "unfavorable_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Gender\n",
      "mapping {'Female': 0, 'Male': 1}\n",
      "Feature Married\n",
      "mapping {'No': 0, 'Yes': 1}\n",
      "Feature Fraud_risk\n",
      "mapping {'Risk': 0, 'Safe': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Education  Fraud_risk\n",
       "0       1        0          1           0\n",
       "1       1        1          1           1\n",
       "2       1        1          1           1\n",
       "3       1        1          0           1\n",
       "4       1        0          1           0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "categorical_column = ['Gender', 'Married', 'Fraud_risk']\n",
    "\n",
    "data_encoded = df.copy(deep=True)\n",
    "#Use Scikit-learn label encoding to encode character data\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "for col in categorical_column:\n",
    "        data_encoded[col] = lab_enc.fit_transform(df[col])\n",
    "        le_name_mapping = dict(zip(lab_enc.classes_, lab_enc.transform(lab_enc.classes_)))\n",
    "        print('Feature', col)\n",
    "        print('mapping', le_name_mapping)\n",
    "        \n",
    "\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside fit transform\n",
      "Feature Gender\n",
      "mapping {0: 0, 1: 1}\n",
      "Feature Married\n",
      "mapping {0: 0, 1: 1}\n",
      "Feature Fraud_risk\n",
      "mapping {0: 0, 1: 1}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from Pipeline_LabelEncoder.sklearn_label_encoder import PipelineLabelEncoder\n",
    "preprocessed_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).fit_transform(data_encoded)\n",
    "print('-------------------------')\n",
    "#print('validation data encoding')\n",
    "#validation_enc_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).transform(validation_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary label dataset that can be used by bias mitigation algorithms\n",
    "fraud_dataset = BinaryLabelDataset(favorable_label=favorable_label,\n",
    "                                unfavorable_label=unfavorable_label,\n",
    "                                df=preprocessed_data,\n",
    "                                label_names=['Fraud_risk'],\n",
    "                                protected_attribute_names=['Gender', 'Married'],\n",
    "                                unprivileged_protected_attributes=unprivileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Data Details"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the training dataset (921, 3)\n",
      "Training data favorable label 1.0\n",
      "Training data unfavorable label 0.0\n",
      "Training data protected attribute ['Gender', 'Married']\n",
      "Training data privileged protected attribute (1:Male and 0:Female) [array([1.]), array([1.])]\n",
      "Training data unprivileged protected attribute (1:Male and 0:Female) [array([0.]), array([0.])]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Training Data Details\"))\n",
    "print(\"shape of the training dataset\", fraud_dataset.features.shape)\n",
    "print(\"Training data favorable label\", fraud_dataset.favorable_label)\n",
    "print(\"Training data unfavorable label\", fraud_dataset.unfavorable_label)\n",
    "print(\"Training data protected attribute\", fraud_dataset.protected_attribute_names)\n",
    "print(\"Training data privileged protected attribute (1:Male and 0:Female)\", \n",
    "      fraud_dataset.privileged_protected_attributes)\n",
    "print(\"Training data unprivileged protected attribute (1:Male and 0:Female)\",\n",
    "      fraud_dataset.unprivileged_protected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_dataset_train, fraud_dataset_test = fraud_dataset.split([0.9], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.371405\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.392308\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(fraud_dataset_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(fraud_dataset_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.371405\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.392308\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "fraud_dataset_train.features = min_max_scaler.fit_transform(fraud_dataset_train.features)\n",
    "fraud_dataset_test.features = min_max_scaler.transform(fraud_dataset_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(fraud_dataset_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(fraud_dataset_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build plan classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "epoch 0; iter: 0; batch classifier loss: 0.782193\n",
      "epoch 1; iter: 0; batch classifier loss: 0.703004\n",
      "epoch 2; iter: 0; batch classifier loss: 0.667041\n",
      "epoch 3; iter: 0; batch classifier loss: 0.630537\n",
      "epoch 4; iter: 0; batch classifier loss: 0.623781\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586897\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552156\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563670\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538822\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493203\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513934\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456346\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475201\n",
      "epoch 13; iter: 0; batch classifier loss: 0.461812\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454768\n",
      "epoch 16; iter: 0; batch classifier loss: 0.448100\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383540\n",
      "epoch 18; iter: 0; batch classifier loss: 0.368943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.433427\n",
      "epoch 20; iter: 0; batch classifier loss: 0.379914\n",
      "epoch 21; iter: 0; batch classifier loss: 0.394100\n",
      "epoch 22; iter: 0; batch classifier loss: 0.344273\n",
      "epoch 23; iter: 0; batch classifier loss: 0.378838\n",
      "epoch 24; iter: 0; batch classifier loss: 0.413154\n",
      "epoch 25; iter: 0; batch classifier loss: 0.405221\n",
      "epoch 26; iter: 0; batch classifier loss: 0.391514\n",
      "epoch 27; iter: 0; batch classifier loss: 0.363655\n",
      "epoch 28; iter: 0; batch classifier loss: 0.380475\n",
      "epoch 29; iter: 0; batch classifier loss: 0.381207\n",
      "epoch 30; iter: 0; batch classifier loss: 0.382444\n",
      "epoch 31; iter: 0; batch classifier loss: 0.334367\n",
      "epoch 32; iter: 0; batch classifier loss: 0.360560\n",
      "epoch 33; iter: 0; batch classifier loss: 0.316437\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350849\n",
      "epoch 35; iter: 0; batch classifier loss: 0.317031\n",
      "epoch 36; iter: 0; batch classifier loss: 0.286585\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388472\n",
      "epoch 38; iter: 0; batch classifier loss: 0.270858\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411010\n",
      "epoch 40; iter: 0; batch classifier loss: 0.292543\n",
      "epoch 41; iter: 0; batch classifier loss: 0.355329\n",
      "epoch 42; iter: 0; batch classifier loss: 0.364937\n",
      "epoch 43; iter: 0; batch classifier loss: 0.348324\n",
      "epoch 44; iter: 0; batch classifier loss: 0.317331\n",
      "epoch 45; iter: 0; batch classifier loss: 0.372181\n",
      "epoch 46; iter: 0; batch classifier loss: 0.318158\n",
      "epoch 47; iter: 0; batch classifier loss: 0.325065\n",
      "epoch 48; iter: 0; batch classifier loss: 0.311022\n",
      "epoch 49; iter: 0; batch classifier loss: 0.379728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fc8472a7b50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(fraud_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the plain model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nodebiasing_train = plain_model.predict(fraud_dataset_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(fraud_dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for the dataset from plain model (without debiasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.509533\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.610577\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.806452\n",
      "Test set: Balanced classification accuracy = 0.802273\n",
      "Test set: Disparate impact = 0.111888\n",
      "Test set: Equal opportunity difference = -0.607143\n",
      "Test set: Average odds difference = -0.449405\n",
      "Test set: Theil_index = 0.152998\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(fraud_dataset_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.657903; batch adversarial loss: 0.573822\n",
      "epoch 1; iter: 0; batch classifier loss: 0.649026; batch adversarial loss: 0.571995\n",
      "epoch 2; iter: 0; batch classifier loss: 0.627158; batch adversarial loss: 0.565493\n",
      "epoch 3; iter: 0; batch classifier loss: 0.628682; batch adversarial loss: 0.589801\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579517; batch adversarial loss: 0.582512\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585141; batch adversarial loss: 0.593441\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585325; batch adversarial loss: 0.628145\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550264; batch adversarial loss: 0.566879\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533809; batch adversarial loss: 0.606753\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566627; batch adversarial loss: 0.610721\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504185; batch adversarial loss: 0.574993\n",
      "epoch 11; iter: 0; batch classifier loss: 0.561196; batch adversarial loss: 0.637756\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504111; batch adversarial loss: 0.549437\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535185; batch adversarial loss: 0.652670\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481608; batch adversarial loss: 0.609813\n",
      "epoch 15; iter: 0; batch classifier loss: 0.452477; batch adversarial loss: 0.567597\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460399; batch adversarial loss: 0.575191\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516890; batch adversarial loss: 0.611271\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487797; batch adversarial loss: 0.619899\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476997; batch adversarial loss: 0.626753\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502222; batch adversarial loss: 0.637091\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491788; batch adversarial loss: 0.580900\n",
      "epoch 22; iter: 0; batch classifier loss: 0.555205; batch adversarial loss: 0.613910\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497394; batch adversarial loss: 0.603605\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512847; batch adversarial loss: 0.580763\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513482; batch adversarial loss: 0.580927\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452528; batch adversarial loss: 0.603268\n",
      "epoch 27; iter: 0; batch classifier loss: 0.452709; batch adversarial loss: 0.561212\n",
      "epoch 28; iter: 0; batch classifier loss: 0.396820; batch adversarial loss: 0.559123\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450322; batch adversarial loss: 0.664573\n",
      "epoch 30; iter: 0; batch classifier loss: 0.410058; batch adversarial loss: 0.610154\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499964; batch adversarial loss: 0.628392\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488456; batch adversarial loss: 0.545984\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446993; batch adversarial loss: 0.513052\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462110; batch adversarial loss: 0.630111\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423605; batch adversarial loss: 0.531587\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390587; batch adversarial loss: 0.610781\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486844; batch adversarial loss: 0.572137\n",
      "epoch 38; iter: 0; batch classifier loss: 0.517211; batch adversarial loss: 0.569596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.667832; batch adversarial loss: 0.604353\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429266; batch adversarial loss: 0.585926\n",
      "epoch 41; iter: 0; batch classifier loss: 0.553771; batch adversarial loss: 0.590515\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467520; batch adversarial loss: 0.636501\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410333; batch adversarial loss: 0.507430\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456807; batch adversarial loss: 0.496192\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458712; batch adversarial loss: 0.549207\n",
      "epoch 46; iter: 0; batch classifier loss: 0.497133; batch adversarial loss: 0.557709\n",
      "epoch 47; iter: 0; batch classifier loss: 0.542181; batch adversarial loss: 0.561947\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429940; batch adversarial loss: 0.542104\n",
      "epoch 49; iter: 0; batch classifier loss: 0.514921; batch adversarial loss: 0.522236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fc80c2c66d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(fraud_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the plain model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_train = debiased_model.predict(fraud_dataset_train)\n",
    "dataset_debiasing_test = debiased_model.predict(fraud_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.509533\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.610577\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.462279\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.450000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.806452\n",
      "Test set: Balanced classification accuracy = 0.802273\n",
      "Test set: Disparate impact = 0.111888\n",
      "Test set: Equal opportunity difference = -0.607143\n",
      "Test set: Average odds difference = -0.449405\n",
      "Test set: Theil_index = 0.152998\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.752688\n",
      "Test set: Balanced classification accuracy = 0.740152\n",
      "Test set: Disparate impact = 1.818182\n",
      "Test set: Equal opportunity difference = 0.232143\n",
      "Test set: Average odds difference = 0.595238\n",
      "Test set: Theil_index = 0.186823\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(fraud_dataset_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have observed how to use AI 360 fairness toolkit to eliminate the bias during preprocessing & inprocessing stages of model building & development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
